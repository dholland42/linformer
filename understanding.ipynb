{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 01:50:30.122068: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-26 01:50:30.124795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-26 01:50:30.124805: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 01:50:31.261727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-26 01:50:31.261756: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-26 01:50:31.261775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b76fc4b7beb9): /proc/driver/nvidia/version does not exist\n",
      "2022-06-26 01:50:31.262023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 16) dtype=float32 (created by layer 'embedding')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = keras.Input(shape=(100,))\n",
    "emb = keras.layers.Embedding(100,16)(inp)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 16) dtype=float32 (created by layer 'multi_head_attention')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = keras.layers.MultiHeadAttention(2, 64)\n",
    "mha(emb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the einsum equations used for transforming the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aecd,abcd->acbe\n",
      "acbe,aecd->abcd\n",
      "abcd,cde->abe\n"
     ]
    }
   ],
   "source": [
    "print(mha._dot_product_equation)\n",
    "print(mha._combine_equation)\n",
    "print(mha._output_dense.get_config()['equation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going into these einsums?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mha._query_dense(emb)\n",
    "k = mha._key_dense(emb)\n",
    "v = mha._value_dense(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 2, 64) dtype=float32 (created by layer 'query')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're all tensors of shape `(None, 100, 2, 16)`, corresponding to `(batch, sequence_len, num_heads, hidden_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input shape is `(None, 100, 16)`.\n",
    "\n",
    "The first thing that happens is a call to `tf.einsum('aecd,abcd->acbe', key, query)`. So let's follow the shapes here.\n",
    "\n",
    "a = None\n",
    "b = 100\n",
    "c = 2\n",
    "d = 16\n",
    "e = 100\n",
    "\n",
    "So the output shape should be `(None, 2, 100, 100)`.\n",
    "\n",
    "Then, there is a call to `tf.einsum('acbe,aecd->abcd', attention, value)`. Again, let's follow the shapes.\n",
    "\n",
    "a = None\n",
    "b = 100\n",
    "c = 2\n",
    "d = 16\n",
    "e = 100\n",
    "\n",
    "So the output shape there should be `(None, 100, 2, 16)`.\n",
    "\n",
    "Then there is a final einsum computation: 'abcd,cde->abe' which brings us back to `(None, 100, 16)`. Let's prove to ourselves that this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 16) dtype=float32 (created by layer 'attention_output')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = tf.einsum('aecd,abcd->acbe', k, q)\n",
    "int = tf.einsum('acbe,aecd->abcd', att, v)\n",
    "out = mha._output_dense(int)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this works. So what happens when we project the sequence length of the key and value tensors to some constant before the einsums?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_transformed = keras.layers.EinsumDense('bsnh,se->benh', output_shape=(32, None, None))(k)\n",
    "v_transformed = keras.layers.EinsumDense('bsnh,sf->bfnh', output_shape=(32, None, None))(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 2, 64) dtype=float32 (created by layer 'einsum_dense')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 16) dtype=float32 (created by layer 'attention_output')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = tf.einsum('aecd,abcd->acbe', k_transformed, q)\n",
    "int = tf.einsum('acbe,aecd->abcd', att, v_transformed)\n",
    "out = mha._output_dense(int)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work, let's try it out! But first let's get a time benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 2000, 256)    25600       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 2000, 256)   1051904     ['embedding_1[0][0]',            \n",
      " eadAttention)                                                    'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,077,504\n",
      "Trainable params: 1,077,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = keras.Input(shape=(2000,))\n",
    "emb = keras.layers.Embedding(100,256)(inp)\n",
    "mha = keras.layers.MultiHeadAttention(8, 128)(emb, emb)\n",
    "model = keras.Model(inp, mha)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]],\n",
       "\n",
       "       [[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]],\n",
       "\n",
       "       [[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]],\n",
       "\n",
       "       [[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]],\n",
       "\n",
       "       [[-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        ...,\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405],\n",
       "        [-0.00235837, -0.00011801, -0.00334762, ...,  0.00549526,\n",
       "         -0.00023075,  0.00329405]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1]*2000]*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it takes about 5-6 seconds to predict on a batch size of 32 with sequence length 2000. Let's try the linformer layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 2000, 256)    25600       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " linear_multi_head_attention (L  (None, 2000, 256)   1179904     ['embedding_1[0][0]',            \n",
      " inearMultiHeadAttention)                                         'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,205,504\n",
      "Trainable params: 1,205,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from linformer.attention import LinearMultiHeadAttention\n",
    "\n",
    "lmha = LinearMultiHeadAttention(8, 128, projection_dim=64)(emb, emb)\n",
    "fast_model = keras.Model(inp, lmha)\n",
    "fast_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 818ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]],\n",
       "\n",
       "       [[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]],\n",
       "\n",
       "       [[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]],\n",
       "\n",
       "       [[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]],\n",
       "\n",
       "       [[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_model.predict([[1]*2000]*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reports a predict time of <1s for our expected max batch size of 25!\n",
    "\n",
    "Theoretically this should scale linearly, so we can look at how long it takes to predict on a batch size of 1 and extrapolate (more or less) from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        ...,\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442],\n",
       "        [ 0.00037992,  0.00090282, -0.00024732, ...,  0.00072621,\n",
       "         -0.00168245, -0.00192442]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_model.predict([[1]*2000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fedae5906b6e2e58904c249a995923bb90775fc6ec4248adb7d463d80b07015"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
